{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ccc4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_loader.ipynb\n",
    "%run utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5159f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5787\n",
      "5787\n",
      "722\n",
      "722\n",
      "727\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "# Number of data\n",
    "print(len(os.listdir('./data/annotations_train/')))\n",
    "print(len(os.listdir('./data/images_train/')))\n",
    "print(len(os.listdir('./data/annotations_val/')))\n",
    "print(len(os.listdir('./data/images_val/')))\n",
    "print(len(os.listdir('./data/annotations_test/')))\n",
    "print(len(os.listdir('./data/images_test/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db331055",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RadarDataset(data_transform, \"./data/images_train/\")\n",
    "val_dataset = RadarDataset(data_transform, \"./data/images_val/\")\n",
    "test_dataset = RadarDataset(data_transform, './data/images_test/')\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, collate_fn=collate_fn, num_workers=1, shuffle=True)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_dataset, batch_size=2, collate_fn=collate_fn, num_workers=1, shuffle=False)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ab47fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_instance_segmentation(2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b03d2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------train start--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.36it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, Train Loss : 0.27164918650907116, Val Loss : 3.8221411589440217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.30it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:06<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2, Train Loss : 0.216572627436779, Val Loss : 0.25769842543492194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.39it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:06<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3, Train Loss : 0.19030094165586672, Val Loss : 0.2230680020954305\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "num_epochs = 3\n",
    "lr=0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "val_epoch_loss_list = []\n",
    "\n",
    "print('----------------------train start--------------------------')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0\n",
    "    val_epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Valdiation data\n",
    "    for imgs, targets in tqdm(val_data_loader, 'Iterating validation dataset'):\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(imgs, targets) \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        val_epoch_loss += losses.item()\n",
    "    mean_val_epoch_loss = val_epoch_loss/len(val_data_loader)\n",
    "\n",
    "    # Train data\n",
    "    for imgs, targets in tqdm(data_loader, 'Iterating training dataset'):\n",
    "        optimizer.zero_grad()\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(imgs, targets) \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    mean_epoch_loss = epoch_loss/len(data_loader)\n",
    "    \n",
    "    train_epoch_loss_list.append(mean_epoch_loss)\n",
    "    val_epoch_loss_list.append(mean_val_epoch_loss)\n",
    "    \n",
    "    # Save\n",
    "    torch.save(model.state_dict(), './model/ex1_'+str(i+1)+'.pt')\n",
    "    print(f'epoch : {i+1}, Train Loss : {mean_epoch_loss}, Val Loss : {mean_val_epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362d77a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------train start--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.39it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:05<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1, Train Loss : 0.1570621297605279, Val Loss : 0.20356635596613473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.38it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:05<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 2, Train Loss : 0.14890742065473803, Val Loss : 0.1889547933424485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:42<00:00,  8.40it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:05<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 3, Train Loss : 0.14487705043881988, Val Loss : 0.18693483630943414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.38it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:07<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 4, Train Loss : 0.1416719438029941, Val Loss : 0.1850819314037994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.30it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:09<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 5, Train Loss : 0.13931854012143574, Val Loss : 0.18571252724635634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.38it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:05<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 6, Train Loss : 0.13762742294443986, Val Loss : 0.18439660808510067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.38it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:06<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 7, Train Loss : 0.1353874421590307, Val Loss : 0.18553678587677572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.30it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:10<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 8, Train Loss : 0.13366124874692728, Val Loss : 0.1853730621337478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.29it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:08<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 9, Train Loss : 0.132329713317946, Val Loss : 0.18722190682639542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating validation dataset: 100%|███████████| 361/361 [00:43<00:00,  8.30it/s]\n",
      "Iterating training dataset: 100%|███████████| 2894/2894 [13:10<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 10, Train Loss : 0.13024149126770346, Val Loss : 0.18749878576432982\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "num_epochs = 10\n",
    "lr=0.000001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "\n",
    "print('----------------------train start--------------------------')\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    start = time.time()\n",
    "    epoch_loss = 0\n",
    "    val_epoch_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    # Valdiation data\n",
    "    for imgs, targets in tqdm(val_data_loader, 'Iterating validation dataset'):\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(imgs, targets) \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        val_epoch_loss += losses.item()\n",
    "    mean_val_epoch_loss = val_epoch_loss/len(val_data_loader)\n",
    "\n",
    "    # Train data\n",
    "    for imgs, targets in tqdm(data_loader, 'Iterating training dataset'):\n",
    "        optimizer.zero_grad()\n",
    "        imgs = list(img.to(device) for img in imgs)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        loss_dict = model(imgs, targets) \n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        epoch_loss += losses.item()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "    mean_epoch_loss = epoch_loss/len(data_loader)\n",
    "    \n",
    "    train_epoch_loss_list.append(mean_epoch_loss)\n",
    "    val_epoch_loss_list.append(mean_val_epoch_loss)\n",
    "    \n",
    "    # Save\n",
    "    torch.save(model.state_dict(), './model/ex1_1_'+str(i+1)+'.pt')\n",
    "    print(f'epoch : {i+1}, Train Loss : {mean_epoch_loss}, Val Loss : {mean_val_epoch_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9d5305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y1 = train_epoch_loss_list\n",
    "y2 = val_epoch_loss_list\n",
    "x = list(range(0,len(y1)))\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(x, y1, label = \"Train\")\n",
    "plt.plot(x, y2, label = \"Validation\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46617b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "i=4\n",
    "model = get_model_instance_segmentation(2)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('./model/ex1_1_'+str(i)+'.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8647f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 727/727 [00:54<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP : 0.9036352738277582\n"
     ]
    }
   ],
   "source": [
    "# AP Caculation\n",
    "labels = []\n",
    "preds_adj_all = []\n",
    "annot_all = []\n",
    "for im, annot in tqdm(test_data_loader, position = 0, leave = True):\n",
    "    im = list(img.to(device) for img in im)\n",
    "    for t in annot:\n",
    "        labels += t['labels']\n",
    "    with torch.no_grad():\n",
    "        preds_adj = make_prediction(model, im, 0.5)\n",
    "        preds_adj = [{k: v.to(torch.device('cpu')) for k, v in t.items()} for t in preds_adj]\n",
    "        preds_adj_all.append(preds_adj)\n",
    "        annot_all.append(annot)\n",
    "sample_metrics = []\n",
    "for batch_i in range(len(preds_adj_all)):\n",
    "    sample_metrics += get_batch_statistics(preds_adj_all[batch_i], annot_all[batch_i], iou_threshold=0.5) \n",
    "true_positives, pred_scores, pred_labels = [torch.cat(x, 0) for x in list(zip(*sample_metrics))]\n",
    "precision, recall, AP, f1, ap_class = ap_per_class(true_positives, pred_scores, pred_labels, torch.tensor(labels))\n",
    "mAP = torch.mean(AP)\n",
    "print(f'AP : {mAP}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a94d305d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.27164918650907116,\n",
       " 0.216572627436779,\n",
       " 0.19030094165586672,\n",
       " 0.1570621297605279,\n",
       " 0.14890742065473803,\n",
       " 0.14487705043881988,\n",
       " 0.1416719438029941,\n",
       " 0.13931854012143574,\n",
       " 0.13762742294443986,\n",
       " 0.1353874421590307,\n",
       " 0.13366124874692728,\n",
       " 0.132329713317946,\n",
       " 0.13024149126770346]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca19b1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.8221411589440217,\n",
       " 0.25769842543492194,\n",
       " 0.2230680020954305,\n",
       " 0.20356635596613473,\n",
       " 0.1889547933424485,\n",
       " 0.18693483630943414,\n",
       " 0.1850819314037994,\n",
       " 0.18571252724635634,\n",
       " 0.18439660808510067,\n",
       " 0.18553678587677572,\n",
       " 0.1853730621337478,\n",
       " 0.18722190682639542,\n",
       " 0.18749878576432982]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951632f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
